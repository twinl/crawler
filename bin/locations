#!/bin/bash
# hourly: run hourly process of collecting data from Twitter
# usage: hourly (from crontab)
# 20101216 erikt(at)xs4all.nl

EXP=locations
BASEDIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )"/.. >/dev/null 2>&1 && pwd )"/
DATADIR="$BASEDIR/$EXP"
LOGDIR="$BASEDIR/etc"
DATE="`date '+%Y%m%d-%H'`"
MIN="`date '+%M'`"
OUTFILE="$DATADIR/$DATE.out.gz"
LANG=en_US.UTF-8
export LANG

cd $DATADIR

if [ "$MIN" = "00" ]
then
   # kill curl if it is running
   ps -ef | grep curl | grep $EXP |\
      tr -s ' ' ' ' | sed 's/^ *//' | cut -d' ' -f2 | xargs kill -9 2>/dev/null
   # wait five seconds
   sleep 10
fi

# check if curl is running
if [ -n "`ps -ef | grep curl | grep $EXP | grep -v grep`" ]
then
   # curl is running, so nothing to do
   exit 0
fi
# no curl is running: restart!

# save previous output after a restart
if [ -f "$OUTFILE" ]
then
   NEWFILE="$OUTFILE.$$.$RANDOM"
   while [ -f "$NEWFILE" ]
   do
      NEWFILE="$OUTFILE.$$.$RANDOM"
   done
   mv $OUTFILE $NEWFILE
fi

find . -perm -060 -exec chmod ug-w {} \;

# start curl
cd $DATADIR
# the next script calls curl
$BASEDIR/bin/makeoauth.locations 2>>$LOGDIR/errorlog | gzip -c > $OUTFILE &

# exit
exit 0
